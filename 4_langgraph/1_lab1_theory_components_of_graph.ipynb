{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome back to Python Notebooks!\n",
    "\n",
    "Didja miss me??\n",
    "\n",
    "### And welcome to Week 4, Day 2 - introducing LangGraph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful constants\n",
    "\n",
    "nouns = [\"Cabbages\", \"Unicorns\", \"Toasters\", \"Penguins\", \"Bananas\", \"Zombies\", \"Rainbows\", \"Eels\", \"Pickles\", \"Muffins\"]\n",
    "adjectives = [\"outrageous\", \"smelly\", \"pedantic\", \"existential\", \"moody\", \"sparkly\", \"untrustworthy\", \"sarcastic\", \"squishy\", \"haunted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our favorite first step! Crew was doing this for us, by the way.\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shout(text: Annotated[str, \"something to be shouted\"]) -> str:\n",
    "    print(text.upper())\n",
    "    return text.upper()\n",
    "\n",
    "shout(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. What is `Annotated`?\n",
    "\n",
    "`Annotated` comes from the Python `typing` module and allows you to attach **metadata** to a data type hint.<br>\n",
    "annotated with type hint and metadata.\n",
    "\n",
    "Syntax:\n",
    "```python\n",
    "Annotated[<data type>, <metadata>]\n",
    "```\n",
    "\n",
    "Example:\n",
    "```python\n",
    "from typing import Annotated\n",
    "\n",
    "UserId = Annotated[int, \"this is a user ID\"]\n",
    "```\n",
    "Here, the base type is `int`, but it carries extra information for frameworks or tools.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. How it works in your code\n",
    "\n",
    "```python\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n",
    "```\n",
    "\n",
    "- `messages` has the **type** `list`.\n",
    "- `add_messages` is **metadata** attached to the field: reducer function for the field in your state.\n",
    "- Pydantic or other libraries can use this metadata for validation, transformation, or documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangGraph needs us to use this feature when we define our State object.\n",
    "\n",
    "It wants us to tell it what function it should call to update the State with a new value.\n",
    "\n",
    "Q. What is **reducer** function?<br>\n",
    "your reducer function (`add_messages`) decides how to combine the new state and old state: it can append it to old state or it can overwrite the old state.<br>\n",
    "you can use builtin reducer functions or you can define custom reducer functions.\n",
    "\n",
    "Q. what does `add_messages` do?<br>\n",
    "A. It adds (appends) new messages to the list of messages (to the list of variable).\n",
    "\n",
    "LangGraph provides a default reducer called `add_messages` which takes care of the most common case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 1: Define the State object\n",
    "\n",
    "You can use any python object;<br>\n",
    "but it's most common to use\n",
    "- a TypedDict or \n",
    "- a Pydantic BaseModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(BaseModel):\n",
    "        \n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. what `messages: Annotated[list, add_messages]` means?<br>\n",
    "A. it is annotated with data type (which is List) and metadata which is the reducer function that I need to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Start the Graph Builder with this State class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiating a state graph passing in state.<br>\n",
    "And one thing to to get your head around here is that what I'm passing in there.it's not an object I'm not instantiating. I'm not I'm not creating a state and passing that in with with messages and so on.<br> \n",
    "Now I'm passing in the class. I'm passing in the type of thing that represents our state. That is what I'm using to create my state graph. And this is beginning the graph building process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a Node\n",
    "\n",
    "A node can be any python function.\n",
    "\n",
    "The reducer that we set before gets automatically called to combine this response with previous responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x752fd4854230>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def our_first_node(old_state: State) -> State:\n",
    "\n",
    "    reply = f\"{random.choice(nouns)} are {random.choice(adjectives)}\"\n",
    "    messages = [{\n",
    "        \"role\": \"assistant\", \n",
    "        \"content\": reply\n",
    "        }]\n",
    "\n",
    "    new_state = State(messages=messages)\n",
    "\n",
    "    return new_state\n",
    "\n",
    "graph_builder.add_node(\"first_node\", our_first_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x752fd4854230>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"first_node\")\n",
    "graph_builder.add_edge(\"first_node\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. what are `START` and `END`?<br>\n",
    "START and END are predefined constants that represent the start and end points of a workflow.<br>\n",
    "In other words, START marks where the workflow begins, and END indicates where it concludes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START: __start__ , END: __end__\n"
     ]
    }
   ],
   "source": [
    "print(f'START: {START} , END: {END}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Compile the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it! Showtime!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, history):\n",
    "    message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages = [message]\n",
    "    state = State(messages=messages)\n",
    "    result = graph.invoke(state)\n",
    "    print(result)\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "# gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. what are types of `Messages` in LangGraph?<br>\n",
    "\n",
    "## Types of Messages in LangGraph\n",
    "\n",
    "LangGraph uses **messages** as structured communication units that flow through the graph.<br>\n",
    "Messages are pre-defined communication units in the graph.<br>\n",
    "They capture user input, model responses, tool outputs, and system instructions — forming the “conversation history” of the workflow.\n",
    "\n",
    "---\n",
    "\n",
    "#### 1. HumanMessage\n",
    "\n",
    "**What it is:** human/ user input, A message sent by a human/user.  \n",
    "**Role:** `user` or `human`.\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "msg = HumanMessage(content=\"What’s the weather like in Vancouver today?\")\n",
    "```\n",
    "\n",
    "**Use case:** When a human initiates a query or gives instructions to the agent.\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. AIMessage\n",
    "\n",
    "**What it is:** AI model response, A message produced by the AI model (LLM).  \n",
    "**Role:** `assistant` or `AI`.\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "msg = AIMessage(content=\"It’s currently 12 °C in Vancouver with clouds and light rain.\")\n",
    "```\n",
    "\n",
    "**Use case:** When the model responds to the user or processes workflow results.\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. SystemMessage\n",
    "\n",
    "**What it is:** system instruction, A message that sets system-level context, instructions, or configuration.  \n",
    "**Role:** `system`.\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "msg = SystemMessage(content=\"You are a helpful assistant specialised in Canadian weather.\")\n",
    "```\n",
    "\n",
    "**Use case:** Used at the start or during workflow to define AI behavior or persona.\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. ToolMessage\n",
    "\n",
    "**What it is:** tool output, Represents the result of a tool invocation.  \n",
    "**Role:** `tool`.\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tool_output = {\"city\": \"Vancouver\", \"temp\": 12, \"condition\": \"cloudy and rain\"}\n",
    "msg = ToolMessage(content=str(tool_output), tool_call_id=\"weather_lookup_123\")\n",
    "```\n",
    "\n",
    "**Use case:** When the graph executes a tool and you want to store its output as part of the state.\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. RemoveMessage\n",
    "\n",
    "**What it is:** Used to programmatically remove previous messages from the history.  \n",
    "**Role:** *(none / system)*\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import RemoveMessage\n",
    "\n",
    "msg = RemoveMessage(id=\"msg_2025_10_19_0001\")\n",
    "```\n",
    "\n",
    "**Use case:** Remove irrelevant or redundant messages to save tokens or fix context errors.\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. AIMessageChunk\n",
    "\n",
    "**What it is:** A chunked or streaming part of an AI response.  \n",
    "**Role:** `assistant (partial)`.\n",
    "\n",
    "```python\n",
    "from langchain_core.messages import AIMessageChunk\n",
    "\n",
    "chunk1 = AIMessageChunk(content=\"Here is the first part of the answer…\")\n",
    "chunk2 = AIMessageChunk(content=\"…and here is the continuation.\")\n",
    "```\n",
    "\n",
    "**Use case:** When streaming partial responses token-by-token.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example Conversation Flow\n",
    "\n",
    "```python\n",
    "SystemMessage(content=\"You are a helpful assistant that answers weather queries in Vancouver.\")\n",
    "HumanMessage(content=\"What’s the weather in Vancouver right now?\")\n",
    "ToolMessage(content=\"{'city': 'Vancouver', 'temp': 12, 'condition': 'cloudy and rain'}\", tool_call_id=\"weather_lookup_1\")\n",
    "AIMessage(content=\"It’s currently 12 °C in Vancouver with cloudy skies and light rain. Would you like the hourly forecast?\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Summary Table:\n",
    "**NOTE**: when you create chat based prompt, your role should be one of the following roles.<br>\n",
    "**NOTE**: based on the role, LangGraph build a coresponding obejct of message. example:\n",
    "```python\n",
    "initial message = State(messages=[{\"role\": \"human\", \"content\": user_input}])\n",
    "```\n",
    "gives `[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}, id='aa')]`\n",
    "\n",
    "\n",
    "| Message Type       | Role (\"who\")        | Use Case                                |\n",
    "|--------------------|---------------------|------------------------------------------|\n",
    "| `HumanMessage`     | user / human        | User asks a question or gives instructions |\n",
    "| `AIMessage`        | assistant / AI      | LLM generates a response                  |\n",
    "| `SystemMessage`    | system              | Set up instructions or global context     |\n",
    "| `ToolMessage`      | tool                | Output of a tool invocation               |\n",
    "| `RemoveMessage`    | (none / system)     | Remove or prune prior messages            |\n",
    "| `AIMessageChunk`   | assistant (partial) | Streaming responses token‑by‑token        |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='What’s the weather like in Vancouver today?' additional_kwargs={} response_metadata={}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "msg = HumanMessage(content=\"What’s the weather like in Vancouver today?\")\n",
    "\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But why did I show you that?\n",
    "\n",
    "To make the point that LangGraph is all about python functions - it doesn't need to involve LLMs!!\n",
    "\n",
    "Now we'll do the 5 steps again, but in 1 shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the State object\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Start the Graph Builder with this State class\n",
    "graph_builder = StateGraph(State)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x752fd4855a90>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create a Node\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def chatbot_node(old_state: State) -> State:\n",
    "    print(f'old message passed to LLM: \\n{old_state}')\n",
    "    response = llm.invoke(old_state.messages)\n",
    "    print(f'response from llm: \\n{response}')\n",
    "    new_state = State(messages=[response])\n",
    "    return new_state\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x752fd4855a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Create Edges\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 5: Compile the Graph\n",
    "graph = graph_builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it! And, let's do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, history):\n",
    "    initial_state = State(messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    result = graph.invoke(initial_state)\n",
    "    print(result)\n",
    "    return result['messages'][-1].content\n",
    "\n",
    "\n",
    "# gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gradio behavior purely in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat started. Type 'exit' to quit.\n",
      "\n",
      "old message passed to LLM: \n",
      "messages=[HumanMessage(content='hi', additional_kwargs={}, response_metadata={}, id='88f56607-e72e-4676-a107-af39a46bf54b')]\n",
      "response from llm: \n",
      "content='Hello! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_ee69c2ef48', 'id': 'chatcmpl-CnuN6eVIVl6V1kxLE1aGs23ZfkX5D', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--de94f4a0-17e0-45b4-a962-73307f43d2c0-0' usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "result in chat function:\n",
      "{'messages': [HumanMessage(content='hi', additional_kwargs={}, response_metadata={}, id='88f56607-e72e-4676-a107-af39a46bf54b'), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_ee69c2ef48', 'id': 'chatcmpl-CnuN6eVIVl6V1kxLE1aGs23ZfkX5D', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--de94f4a0-17e0-45b4-a962-73307f43d2c0-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "Assistant: Hello! How can I assist you today?\n",
      "\n",
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def chat(user_input: str, history):\n",
    "    # Initialize the graph state with a new user message\n",
    "    initial_state = State(messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    \n",
    "    # Run the LangGraph\n",
    "    result = graph.invoke(initial_state)\n",
    "    print(f'result in chat function:\\n{result}')\n",
    "    \n",
    "    # result[\"messages\"] is likely a list of `BaseMessage` objects (AIMessage, HumanMessage, etc.)\n",
    "    last_msg = result[\"messages\"][-1]\n",
    "    \n",
    "    # Safely get the text content depending on object type\n",
    "    content = getattr(last_msg, \"content\", None)\n",
    "    if content is None and isinstance(last_msg, dict):\n",
    "        content = last_msg.get(\"content\")\n",
    "    \n",
    "    return content\n",
    "\n",
    "\n",
    "def run_chat():\n",
    "    print(\"Chat started. Type 'exit' to quit.\\n\")\n",
    "    history = []\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"Chat ended.\")\n",
    "            break\n",
    "\n",
    "        response = chat(user_input, history)\n",
    "        history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        print(f\"Assistant: {response}\\n\")\n",
    "\n",
    "\n",
    "# Run the chat\n",
    "run_chat()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat started. Type 'exit' to quit.\n",
      "\n",
      "old message passed to LLM: \n",
      "messages=[AIMessage(content='hi', additional_kwargs={}, response_metadata={}, id='aefe7ca1-9708-42e5-b933-8eeb4e00c794')]\n",
      "response from llm: \n",
      "content='Hello! How can I assist you today?' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CSdIodgXeoY7AUCO8vEfXb0a8GlUp', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--43a09595-7eb5-4773-afc4-a77e9cba0f63-0' usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "result in chat function:\n",
      "{'messages': [AIMessage(content='hi', additional_kwargs={}, response_metadata={}, id='aefe7ca1-9708-42e5-b933-8eeb4e00c794'), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 8, 'total_tokens': 17, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_51db84afab', 'id': 'chatcmpl-CSdIodgXeoY7AUCO8vEfXb0a8GlUp', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--43a09595-7eb5-4773-afc4-a77e9cba0f63-0', usage_metadata={'input_tokens': 8, 'output_tokens': 9, 'total_tokens': 17, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "Assistant: Hello! How can I assist you today?\n",
      "\n",
      "old message passed to LLM: \n",
      "messages=[AIMessage(content='tell me about yourself in one line', additional_kwargs={}, response_metadata={}, id='4382f6e5-82a4-469b-84c7-2e0919d06f46')]\n",
      "response from llm: \n",
      "content='I am an AI language model designed to assist with providing information, answering questions, and engaging in conversations on a wide range of topics!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 14, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CSdJ1KQTQLTI0s90J2pfSbzWpPUiX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--01808494-3e63-4f7c-bf8f-3aa4ba3f0e2c-0' usage_metadata={'input_tokens': 14, 'output_tokens': 27, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "result in chat function:\n",
      "{'messages': [AIMessage(content='tell me about yourself in one line', additional_kwargs={}, response_metadata={}, id='4382f6e5-82a4-469b-84c7-2e0919d06f46'), AIMessage(content='I am an AI language model designed to assist with providing information, answering questions, and engaging in conversations on a wide range of topics!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 14, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'id': 'chatcmpl-CSdJ1KQTQLTI0s90J2pfSbzWpPUiX', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--01808494-3e63-4f7c-bf8f-3aa4ba3f0e2c-0', usage_metadata={'input_tokens': 14, 'output_tokens': 27, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "Assistant: I am an AI language model designed to assist with providing information, answering questions, and engaging in conversations on a wide range of topics!\n",
      "\n",
      "Chat ended.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def chat(user_input: str, history):\n",
    "    # Initialize the graph state with a new user message\n",
    "    initial_state = State(messages=[{\"role\": \"ai\", \"content\": user_input}])\n",
    "    \n",
    "    # Run the LangGraph\n",
    "    result = graph.invoke(initial_state)\n",
    "    print(f'result in chat function:\\n{result}')\n",
    "    \n",
    "    # result[\"messages\"] is likely a list of `BaseMessage` objects (AIMessage, HumanMessage, etc.)\n",
    "    last_msg = result[\"messages\"][-1]\n",
    "    \n",
    "    # Safely get the text content depending on object type\n",
    "    content = getattr(last_msg, \"content\", None)\n",
    "    if content is None and isinstance(last_msg, dict):\n",
    "        content = last_msg.get(\"content\")\n",
    "    \n",
    "    return content\n",
    "\n",
    "\n",
    "def run_chat():\n",
    "    print(\"Chat started. Type 'exit' to quit.\\n\")\n",
    "    history = []\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "        if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "            print(\"Chat ended.\")\n",
    "            break\n",
    "\n",
    "        response = chat(user_input, history)\n",
    "        history.append({\"role\": \"user\", \"content\": user_input})\n",
    "        history.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "        print(f\"Assistant: {response}\\n\")\n",
    "\n",
    "\n",
    "# Run the chat\n",
    "run_chat()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
